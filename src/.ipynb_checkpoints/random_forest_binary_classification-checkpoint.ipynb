{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://spark.apache.org/docs/latest/sql-programming-guide.html#sql\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"TestApp\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading csv file using SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "import pyspark\n",
    "\n",
    "df = spark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('gen.csv')\n",
    "\n",
    "df.cache()\n",
    "# Register the DataFrame as a SQL temporary view\n",
    "df.createOrReplaceTempView(\"gen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- c0: double (nullable = true)\n",
      " |-- c1: double (nullable = true)\n",
      " |-- c2: double (nullable = true)\n",
      " |-- c3: double (nullable = true)\n",
      " |-- c4: double (nullable = true)\n",
      " |-- c5: double (nullable = true)\n",
      " |-- c6: double (nullable = true)\n",
      " |-- c7: double (nullable = true)\n",
      " |-- c8: double (nullable = true)\n",
      " |-- c9: double (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+-------------------+--------------------+-------------------+--------------------+-----+\n",
      "|                  c0|                  c1|                  c2|                 c3|                  c4|                 c5|                 c6|                  c7|                 c8|                  c9|label|\n",
      "+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+-------------------+--------------------+-------------------+--------------------+-----+\n",
      "| -0.5818906172019618| 0.06428818034683818| -0.2761923630683961| 0.6718147593887743|  1.0920095988722633|-0.6568081717744917| -0.773231768127305|  1.7764854943968649| 0.9271374696145964| -0.4244546552314705|    1|\n",
      "| -2.1328297811774832|  1.3529960238222913|-0.26488382717008113| 0.4275415782422321| -1.1457996293525423| 1.2873501140005958|0.11501049749712955|  0.9672409929929762|-0.9312181098710113|  0.5245282617771482|    0|\n",
      "| -0.5668967878439948|  0.8239433756074305|-0.05412970908830194|-1.2855890670772407|  1.0330423502861812| -1.972572187311033|0.02337762137029659|-0.30210813833322847|-0.5379400020257199|-0.21785008699633351|    1|\n",
      "|  0.9267380980974851|-0.28640791884465433| -0.5528172593280584|0.20128220867643987|   -1.41704111558412|0.32141781983319273|-0.6017664446283723| 0.09116388001574129| 0.4796651282350716|  1.7249319690637592|    0|\n",
      "| -0.6586628341664812|-0.41882244233434707| 0.41696583246798496| -1.487653109293378|  0.8273195697329444| 0.5495522041812949|-0.1853129046753318|  0.7080848810720778| -0.833842608955726|  0.6125759258554863|    1|\n",
      "| 0.26270680319776346| 0.46694035107555604|  0.6301825369829871| -0.860906453460418|-0.24299179152893569|   1.86000484860047| 0.4124515846171261|  0.0603721581999865|0.17840318816697837|  0.6592441750337354|    0|\n",
      "| -1.8490741477864192| -0.1333900423239349|-0.11660103357772732| 1.6910499532589505| -0.3392041729788693|0.11195181211350581|-0.3398797004483011|  0.5898533986177664|-0.9309679424089946| -0.2765078895479712|    0|\n",
      "| -2.0059958273414034|-0.22555212792472606| -2.6058858960599665|0.43222752417895227|  1.1502830426552233| -0.741111901425589| -0.518329990217434|-0.48840612416530305|-0.5751315255762424| -0.5582669529463834|    1|\n",
      "|-0.12326866289641163|  0.5051677662811811| 0.08108494521816095|  1.598776796698159| -1.9002485317450968| 0.5280809211027077| -0.675090522231222| 0.08516911342828772|0.39624964926279543| -1.3514917285329373|    0|\n",
      "| -1.2764665813714955|  0.8166794745011788|   -0.44886581799793|-0.7239199498927736|  1.0327044197233655|-0.1904722581083792| 2.7141093249854142|  0.4636061753764401|0.22994219582976402|  1.4364978457947812|    1|\n",
      "+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+-------------------+--------------------+-------------------+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.show(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'label']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('c0', 'double'),\n",
       " ('c1', 'double'),\n",
       " ('c2', 'double'),\n",
       " ('c3', 'double'),\n",
       " ('c4', 'double'),\n",
       " ('c5', 'double'),\n",
       " ('c6', 'double'),\n",
       " ('c7', 'double'),\n",
       " ('c8', 'double'),\n",
       " ('c9', 'double'),\n",
       " ('label', 'int')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df.columns)\n",
    "display(df.dtypes)\n",
    "df.sample(False, 0.3).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Simple SQL using SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                  c1|label|\n",
      "+--------------------+-----+\n",
      "| 0.06428818034683818|    1|\n",
      "|  1.3529960238222913|    0|\n",
      "|  0.8239433756074305|    1|\n",
      "|-0.28640791884465433|    0|\n",
      "|-0.41882244233434707|    1|\n",
      "| 0.46694035107555604|    0|\n",
      "| -0.1333900423239349|    0|\n",
      "|-0.22555212792472606|    1|\n",
      "|  0.5051677662811811|    0|\n",
      "|  0.8166794745011788|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.06428818034683818, 1),\n",
       " (1.3529960238222913, 0),\n",
       " (0.8239433756074305, 1),\n",
       " (-0.28640791884465433, 0),\n",
       " (-0.41882244233434707, 1),\n",
       " (0.46694035107555604, 0),\n",
       " (-0.1333900423239349, 0),\n",
       " (-0.22555212792472606, 1),\n",
       " (0.5051677662811811, 0),\n",
       " (0.8166794745011788, 1),\n",
       " (-0.13272954993281647, 0),\n",
       " (0.03153938761529191, 1),\n",
       " (-0.6866031297548427, 1),\n",
       " (1.0967836176497179, 0),\n",
       " (1.0054612530350273, 1),\n",
       " (1.3001850807334896, 0),\n",
       " (-0.6795394749289622, 0),\n",
       " (1.4097054742972168, 0),\n",
       " (-0.6659808992622139, 0),\n",
       " (0.5232745995878693, 1),\n",
       " (0.13039370231405742, 0),\n",
       " (-0.3442160867877221, 0),\n",
       " (-0.2058430589149328, 0),\n",
       " (1.8158952412146447, 1),\n",
       " (-0.46970924421213306, 0),\n",
       " (-0.8548799464679143, 1),\n",
       " (-1.1495712377429472, 1),\n",
       " (0.1058375828979097, 1),\n",
       " (0.5976307224713343, 1),\n",
       " (-1.7543729612604253, 1),\n",
       " (-1.5297508788661296, 1),\n",
       " (-1.1717775197847766, 0),\n",
       " (-0.7237153197266217, 1),\n",
       " (1.074461857166102, 1),\n",
       " (0.0086594192939135, 1),\n",
       " (-0.5892380768249048, 0),\n",
       " (-1.4560898793026924, 0),\n",
       " (1.1823939404796393, 1),\n",
       " (-0.08021071179156003, 1),\n",
       " (0.2781777425862949, 1),\n",
       " (0.2829712889822183, 0),\n",
       " (2.2197689554661877, 0),\n",
       " (0.09075529938023236, 0),\n",
       " (0.1316133444038167, 0),\n",
       " (-0.6968164701736839, 0),\n",
       " (-0.4885856613362935, 1),\n",
       " (0.4812937196999528, 0),\n",
       " (1.0604915207005312, 1),\n",
       " (2.280418608982429, 1),\n",
       " (-0.2571714784940396, 1),\n",
       " (0.11835635783037327, 1),\n",
       " (0.953966371574829, 0),\n",
       " (-1.261043113044343, 1),\n",
       " (-0.9746357026266477, 0),\n",
       " (-2.4592816020671187, 0),\n",
       " (-0.6696689268114607, 0),\n",
       " (0.2673084760850625, 0),\n",
       " (-0.22377383891421906, 0),\n",
       " (0.4801468527676887, 1),\n",
       " (-1.9197970218087448, 0),\n",
       " (1.7824859506009527, 0),\n",
       " (-0.20125008767573974, 0),\n",
       " (-0.5635493489596015, 1),\n",
       " (-1.1919998982910485, 0),\n",
       " (-1.5200327289763937, 1),\n",
       " (-1.2597041308078833, 1),\n",
       " (-0.3323911117633173, 0),\n",
       " (-0.21701447126619577, 0),\n",
       " (-1.1320091333280982, 1),\n",
       " (0.26380434487394644, 1),\n",
       " (-1.1576242092458424, 0),\n",
       " (-0.32340914067152493, 1),\n",
       " (-0.8190554787752983, 0),\n",
       " (-0.27884491458489696, 1),\n",
       " (-0.7164650820244339, 1),\n",
       " (-0.396796167772885, 1),\n",
       " (-1.3605983478227686, 0),\n",
       " (0.07540423110962563, 1),\n",
       " (1.0397437304127766, 0),\n",
       " (0.03343327718140015, 1),\n",
       " (-0.20411520013101508, 1),\n",
       " (-0.0008908378997140914, 1),\n",
       " (-1.1608505233497781, 0),\n",
       " (-0.566023080934193, 0),\n",
       " (-0.09620601787108744, 1),\n",
       " (0.5663467227873995, 1),\n",
       " (-0.026182373466608694, 0),\n",
       " (-0.18429720299268615, 0),\n",
       " (0.9660233397596328, 0),\n",
       " (-0.32981296791112513, 1),\n",
       " (0.8596599846966521, 0),\n",
       " (1.421038681573694, 1),\n",
       " (1.1701166629555297, 0),\n",
       " (-0.10446170335296306, 1),\n",
       " (-0.1687627851350876, 0),\n",
       " (0.017317072958511204, 1),\n",
       " (0.888803155795129, 0),\n",
       " (0.8252008763148952, 1),\n",
       " (-0.7591792005827408, 0),\n",
       " (0.5331071974681983, 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlDF = sqlContext.sql(\"SELECT c1, label FROM gen\") # or df.select([c1, label])\n",
    "sqlDF.show(10)\n",
    "\n",
    "c1 = list(map(lambda r : r['c1'], sqlDF.collect()))\n",
    "label = list(map(lambda r : r['label'], sqlDF.collect()))\n",
    "list(zip(c1, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                  c1|\n",
      "+--------------------+\n",
      "| 0.06428818034683818|\n",
      "|  1.3529960238222913|\n",
      "|  0.8239433756074305|\n",
      "|-0.28640791884465433|\n",
      "|-0.41882244233434707|\n",
      "| 0.46694035107555604|\n",
      "| -0.1333900423239349|\n",
      "|-0.22555212792472606|\n",
      "|  0.5051677662811811|\n",
      "|  0.8166794745011788|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+\n",
      "|label|\n",
      "+-----+\n",
      "|    1|\n",
      "|    0|\n",
      "|    1|\n",
      "|    0|\n",
      "|    1|\n",
      "|    0|\n",
      "|    0|\n",
      "|    1|\n",
      "|    0|\n",
      "|    1|\n",
      "+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"c1\").show(10)\n",
    "df.select(['label']).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|                 c1|                  c2|\n",
      "+-------------------+--------------------+\n",
      "|0.06428818034683818| -0.2761923630683961|\n",
      "| 1.3529960238222913|-0.26488382717008113|\n",
      "| 0.8239433756074305|-0.05412970908830194|\n",
      "|0.46694035107555604|  0.6301825369829871|\n",
      "| 0.5051677662811811| 0.08108494521816095|\n",
      "| 0.8166794745011788|   -0.44886581799793|\n",
      "|0.03153938761529191|  0.9819524616870424|\n",
      "| 1.0967836176497179|  1.5357818984553249|\n",
      "| 1.0054612530350273| -1.1415938294150696|\n",
      "| 1.3001850807334896|  -2.261616072256548|\n",
      "+-------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['c1'] > 0).select(['c1', 'c2']).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Datafram to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.352996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.823943</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.286408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.418822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.466940</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.133390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.225552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.505168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.816679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c1  label\n",
       "0  0.064288      1\n",
       "1  1.352996      0\n",
       "2  0.823943      1\n",
       "3 -0.286408      0\n",
       "4 -0.418822      1\n",
       "5  0.466940      0\n",
       "6 -0.133390      0\n",
       "7 -0.225552      1\n",
       "8  0.505168      0\n",
       "9  0.816679      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlDF.toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a new Column on DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'label', 'dc0']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df.withColumn('dc0', df['c0'])\n",
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(c0=-0.5818906172019618, c1=0.06428818034683818, c2=-0.2761923630683961, c3=0.6718147593887743, c4=1.0920095988722633, c5=-0.6568081717744917, c6=-0.773231768127305, c7=1.7764854943968649, c8=0.9271374696145964, c9=-0.4244546552314705, label=1, dc0=-0.5818906172019618)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Transformation using UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "my_f = udf(lambda x : 5 - x * x, FloatType())\n",
    "\n",
    "df_new = df.withColumn('test', my_f(df['c0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      test|\n",
      "+----------+\n",
      "|  4.661403|\n",
      "|0.45103714|\n",
      "|  4.678628|\n",
      "| 4.1411567|\n",
      "|  4.566163|\n",
      "|  4.930985|\n",
      "| 1.5809247|\n",
      "|0.97598076|\n",
      "| 4.9848046|\n",
      "| 3.3706331|\n",
      "+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'label', 'test']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.select(['test']).show(10)\n",
    "df_new.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop a Column from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'label']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df_new.drop('test')\n",
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a = df.rdd.map(lambda x: x['c1'])\n",
    "# a.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema of DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(c0,DoubleType,true),StructField(label,IntegerType,true)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StructField(c0,DoubleType,true)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DoubleType"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = df[['c0', 'label']]\n",
    "\n",
    "s = l.schema\n",
    "\n",
    "a = s.fields[0]\n",
    "display(s)\n",
    "display(a)\n",
    "display(a.dataType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Columns by Types and Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_cols_by_type(df, func):\n",
    "    lst = list(filter(func, df.dtypes))\n",
    "    return list(map(lambda field : field[0], lst))\n",
    "\n",
    "def filter_cols_by_name(df, func):\n",
    "    return list(filter(func, df.columns))\n",
    "    \n",
    "cols = filter_cols_by_type(df, lambda field: field[1] == 'double')\n",
    "display(cols)\n",
    "\n",
    "cols = filter_cols_by_name(df, lambda field: 'label' in field)\n",
    "display(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c0', 'double'),\n",
       " ('c1', 'double'),\n",
       " ('c2', 'double'),\n",
       " ('c3', 'double'),\n",
       " ('c4', 'double'),\n",
       " ('c5', 'double'),\n",
       " ('c6', 'double'),\n",
       " ('c7', 'double'),\n",
       " ('c8', 'double'),\n",
       " ('c9', 'double'),\n",
       " ('label', 'int')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'label']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.dtypes)\n",
    "display(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(c0,DoubleType,true),StructField(c1,DoubleType,true),StructField(c2,DoubleType,true),StructField(c3,DoubleType,true),StructField(c4,DoubleType,true),StructField(c5,DoubleType,true),StructField(c6,DoubleType,true),StructField(c7,DoubleType,true),StructField(c8,DoubleType,true),StructField(c9,DoubleType,true),StructField(label,IntegerType,true)))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint'),\n",
       " ('category', 'string'),\n",
       " ('ext', 'string'),\n",
       " ('price', 'double')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['category']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+-----+--------------+\n",
      "| id|category|ext|price|category_index|\n",
      "+---+--------+---+-----+--------------+\n",
      "|  0|       a|aaa|  NaN|           0.0|\n",
      "|  1|       b|bbb|  NaN|           2.0|\n",
      "|  2|       c|ccc|  NaN|           1.0|\n",
      "|  3|       a|aaa|  NaN|           0.0|\n",
      "|  4|       a|aaa|  NaN|           0.0|\n",
      "|  5|       c|ccc|  1.0|           1.0|\n",
      "+---+--------+---+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "def __create_string_indexers(df, cols):\n",
    "    indexers = []\n",
    "    fmt = '{}_index'\n",
    "    for c in cols:\n",
    "        indexer = StringIndexer(inputCol=c, outputCol=fmt.format(c))\n",
    "        indexers.append(indexer)\n",
    "    \n",
    "    return indexers\n",
    "    \n",
    "def create_string_indexers(df, ex_cols=None):\n",
    "    cols = filter_cols_by_type(df, lambda field: field[1] == 'string')\n",
    "    if ex_cols is not None:\n",
    "        for c in ex_cols:\n",
    "            if c in cols:\n",
    "                cols.remove(c)\n",
    "    indexers = __create_string_indexers(df, cols)\n",
    "    return cols, indexers\n",
    "    \n",
    "\n",
    "df_sample = spark.createDataFrame(\n",
    "    [(0, \"a\", 'aaa', float(\"nan\")), \n",
    "     (1, \"b\", 'bbb', float(\"nan\")), \n",
    "     (2, \"c\", 'ccc', float(\"nan\")), \n",
    "     (3, \"a\", 'aaa', float(\"nan\")), \n",
    "     (4, \"a\", 'aaa', float(\"nan\")), \n",
    "     (5, \"c\", 'ccc', 1.0)],\n",
    "    [\"id\", \"category\", 'ext', 'price'])\n",
    "\n",
    "display(df_sample.dtypes)\n",
    "\n",
    "cols, indexers = create_string_indexers(df_sample, ['ext'])\n",
    "display(cols)\n",
    "\n",
    "pipe = Pipeline(stages=indexers)\n",
    "df_indexed = pipe.fit(df_sample).transform(df_sample)\n",
    "df_indexed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------+----+-----+\n",
      "|summary|                id|category| ext|price|\n",
      "+-------+------------------+--------+----+-----+\n",
      "|  count|                 6|       6|   6|    6|\n",
      "|   mean|               2.5|    null|null|  NaN|\n",
      "| stddev|1.8708286933869707|    null|null|  NaN|\n",
      "|    min|                 0|       a| aaa|  1.0|\n",
      "|    max|                 5|       c| ccc|  NaN|\n",
      "+-------+------------------+--------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sample.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+-----+\n",
      "| id|category|ext|price|\n",
      "+---+--------+---+-----+\n",
      "|  5|       c|ccc|  1.0|\n",
      "+---+--------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sample.dropna().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Imputer To Fill Missing Values - nan (none), null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------------------+-----+\n",
      "|   a|  b|             out_a|out_b|\n",
      "+----+---+------------------+-----+\n",
      "| 1.0|NaN|               1.0|  4.0|\n",
      "| 2.0|NaN|               2.0|  4.0|\n",
      "|null|3.0|2.3333333333333335|  3.0|\n",
      "| 4.0|4.0|               4.0|  4.0|\n",
      "|null|5.0|2.3333333333333335|  5.0|\n",
      "+----+---+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (1.0, float(\"nan\")),\n",
    "    (2.0, float(\"nan\")),\n",
    "    (None, 3.0),\n",
    "    (4.0, 4.0),\n",
    "    (None, 5.0)\n",
    "], [\"a\", \"b\"])\n",
    "\n",
    "imputer = Imputer(inputCols=[\"a\", \"b\"], outputCols=[\"out_a\", \"out_b\"])\n",
    "model = imputer.fit(df)\n",
    "\n",
    "model.transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  a|  b|\n",
      "+---+---+\n",
      "|4.0|4.0|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropna().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=df['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.filter(a.isNotNull()).count() == df.filter(df.a.isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.filter(~a.isNotNull()).count() == df.filter(~df.a.isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(a)|\n",
      "+--------+\n",
      "|       3|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('df123')\n",
    "spark.sql('select count(a) from df123 where a is not null').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark\n",
    "# sc = pyspark.SparkContext('local[*]')\n",
    "\n",
    "# # do something to prove it works\n",
    "# rdd = sc.parallelize(range(1000))\n",
    "# rdd.takeSample(False, 5)\n",
    "\n",
    "# ======================================\n",
    "\n",
    "\n",
    "# # !cat /opt/conda/LICENSE.txt\n",
    "\n",
    "# RDDread = sc.textFile (\"/opt/conda/LICENSE.txt\")\n",
    "# RDDread.collect()\n",
    "# RDDread.first()\n",
    "# RDDread.sample(True, 0.33).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
